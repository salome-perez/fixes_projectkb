public class LocalContainerLauncher {
    private void runSubtask(org.apache.hadoop.mapred.Task task,
                            final TaskType taskType,
                            TaskAttemptId attemptID,
                            final int numMapTasks,
                            boolean renameOutputs,
                            Map<TaskAttemptID, MapOutputFile> localMapFiles)
    throws RuntimeException, IOException {
        org.apache.hadoop.mapred.TaskAttemptID classicAttemptID =
            TypeConverter.fromYarn(attemptID);

        try {
        JobConf conf = new JobConf(getConfig());
        conf.set(JobContext.TASK_ID, task.getTaskID().toString());
        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());
        conf.setBoolean(JobContext.TASK_ISMAP, (taskType == TaskType.MAP));
        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());
        conf.set(JobContext.ID, task.getJobID().toString());

        // Use the AM's local dir env to generate the intermediate step 
        // output files
        String[] localSysDirs = StringUtils.getTrimmedStrings(
            System.getenv(Environment.LOCAL_DIRS.name()));
        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);
        LOG.info(MRConfig.LOCAL_DIR + " for uber task: "
            + conf.get(MRConfig.LOCAL_DIR));

        // mark this as an uberized subtask so it can set task counter
        // (longer-term/FIXME:  could redefine as job counter and send
        // "JobCounterEvent" to JobImpl on [successful] completion of subtask;
        // will need new Job state-machine transition and JobImpl jobCounters
        // map to handle)
        conf.setBoolean("mapreduce.task.uberized", true);

        // Check and handle Encrypted spill key
        task.setEncryptedSpillKey(encryptedSpillKey);
        YarnChild.setEncryptedSpillKeyIfRequired(task);

        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,
        // etc.), or just assume/hope the state machine(s) and uber-AM work
        // as expected?
        if (taskType == TaskType.MAP) {
            if (doneWithMaps) {
            LOG.error("CONTAINER_REMOTE_LAUNCH contains a map task ("
                        + attemptID + "), but should be finished with maps");
            throw new RuntimeException();
            }

            MapTask map = (MapTask)task;
            map.setConf(conf);

            map.run(conf, umbilical);

            if (renameOutputs) {
            MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID,
                map.getMapOutputFile());
            localMapFiles.put(classicAttemptID, renamed);
            }
            relocalize();

            if (++finishedSubMaps == numMapTasks) {
            doneWithMaps = true;
            }

        } else /* TaskType.REDUCE */ {

            if (!doneWithMaps) {
            // check if event-queue empty?  whole idea of counting maps vs. 
            // checking event queue is a tad wacky...but could enforce ordering
            // (assuming no "lost events") at LocalMRAppMaster [CURRENT BUG(?): 
            // doesn't send reduce event until maps all done]
            LOG.error("CONTAINER_REMOTE_LAUNCH contains a reduce task ("
                        + attemptID + "), but not yet finished with maps");
            throw new RuntimeException();
            }

            // a.k.a. "mapreduce.jobtracker.address" in LocalJobRunner:
            // set framework name to local to make task local
            conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);
            conf.set(MRConfig.MASTER_ADDRESS, "local");  // bypass shuffle

            ReduceTask reduce = (ReduceTask)task;
            reduce.setLocalMapFiles(localMapFiles);
            reduce.setConf(conf);          

            reduce.run(conf, umbilical);
            relocalize();
        }

        } catch (FSError e) {
        LOG.fatal("FSError from child", e);
        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us
        if (!ShutdownHookManager.get().isShutdownInProgress()) {
            umbilical.fsError(classicAttemptID, e.getMessage());
        }
        throw new RuntimeException();

        } catch (Exception exception) {
        LOG.warn("Exception running local (uberized) 'child' : "
            + StringUtils.stringifyException(exception));
        try {
            if (task != null) {
            // do cleanup for the task
            task.taskCleanup(umbilical);
            }
        } catch (Exception e) {
            LOG.info("Exception cleaning up: "
                + StringUtils.stringifyException(e));
        }
        // Report back any failures, for diagnostic purposes
        umbilical.reportDiagnosticInfo(classicAttemptID, 
            StringUtils.stringifyException(exception));
        throw new RuntimeException();

        } catch (Throwable throwable) {
        LOG.fatal("Error running local (uberized) 'child' : "
            + StringUtils.stringifyException(throwable));
        if (!ShutdownHookManager.get().isShutdownInProgress()) {
            Throwable tCause = throwable.getCause();
            String cause =
                (tCause == null) ? throwable.getMessage() : StringUtils
                    .stringifyException(tCause);
            umbilical.fatalError(classicAttemptID, cause);
        }
        throw new RuntimeException();
        }
    }
}